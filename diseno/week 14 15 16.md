## Week 14

### Ejercicio #9

Patrones de diseño de Agentes para AI. Uno de los retos más importantes que debe lograr diseñar en su caso #3 es dado un conjunto de 1 o más datasets que sean agregados al datalake, el diseño del modelo de datos se transforma, optimiza y rediseña utilizando la semántica de los datos. Es decir que, la AI por la interpretación de los datos, y los metadatos suministrados en los datasets; determina que:
- hay que realizar un merge de datasets
- algun dataset se va a agregar como columnas de 1 o más datasets
- se crean nuevas relaciones (llaves foráneas, sobre campos llave y no llave)
- nuevos índices deben ser generados
- se van a renombrar columnas 

Dado un patrón de diseño de agentic AI que se le va a ser asignado, proponga una solución al problema anterior que incluya:

1. Integrantes 
2. Nombre del patrón asignado
3. Metáfora del mundo real con los componentes del patrón 
4. Diagrama del patrón usando sus propios nombres de classes, que sea claro los "inputs", el "result output" y en punto donde se hace la interacción con el LLM o Servicio de AI.

https://lekha-bhan88.medium.com/introduction-to-agentic-ai-and-its-design-patterns-af8b7b3ef738

jami-pura-vida, Reactive Pattern

caso3-alex-fran, Goal-Oriented Pattern

data-pura-vida-2, Hierarchical Pattern

team-jumanji, Learning-Based Pattern

team-one, Collaborative Pattern

jerremy,  Collaborative Pattern

El trabajo es grupal con el mismo grupo del caso #3, enviar un mensaje directo al profesor con la respuesta incluyendo los 4 puntos solicitados, antes de las 9:20am

### Ejercicio #10

Este ejercicio deberá hacerse en dos partes, la primer parte es estudiar conceptualmente de que tratan los patrones arquitectónicos de cloud del siguiente artículo: https://learn.microsoft.com/en-us/azure/architecture/patterns/ , es requisito entenderlos para poder desarrollar el ejercicio la lección siguiente.

Seguidamente, se le presentarán 2 problemas del caso #3, a los cuales les diseñará una solución utilizando dos patrones diferentes de los expuestos en el link estudiado. Para aquellos que están en grupos de 2 personas o menos pueden hacer un solo problema. La respuesta debe incluir:

1. Integrantes
2. para cada problema: 

    2.1 patrón a utilizar 

    2.2 diagrama de classes internas del sistema necesarias para implementar el patrón, conectadas a los componentes del cloud necesarios para implementar el patrón, con comentarios que permitan identificar como funciona el patrón y flujo de trabajo del mismo para resolver el problema en cuestión 

    2.3 archivo de chat history de prompts con una AI usados para resolver el diseño. Se consideraran más valiosos aquellos prompts donde el grupo demuestra dominio sobre el patrón guiando a la AI, el qué y cómo quieren las salidas del diseño, y menos valioso aquellos que dejen los criterios de diseño en manos de la AI. 


**Problemas**

- a) Una vez que se haya terminado de obtener los cambios estructurales del modelo de datos que se resolvió en el ejercio #9, ahora se quiere garantizar que dichos cambios de definición del modelo se realicen bajo el principio de "todo o nada", en el caso de que falle, debe transferir el proceso a un humano, arquitecto de datos que se encargará de realizar los ajustes transformacionales y reglas de carga manualmente. En caso de que si resulte exitoso, entonces ahora proceder a la carga de datos en el modelo ya reestructurado, y que sea si y solo si dicha transferencia sea exitosa, la transformación del modelo y sus datos se publica y se hace oficial, de lo contrario todo se deshace y pasa a reingeniería de datos manual. 

- b) cuando se sube un dataset, este puede venir de diferentes fuentes, cuando se trata de archivos de gran tamaño como decir 500MB, 4GB, 10GB, o bien de lecturas de tablas de millones de registros, existe una gran posibilidad de múltiples desconexiones durante la transferencia de los datos. Es necesario que todos los datos se suban al datalake intactos y sin repeticiones de datos sin tener que hacer retrabajo. 


Entregar al profesor por un mensaje directo en Slack del grupo del caso #3 antes de las 9:20am
